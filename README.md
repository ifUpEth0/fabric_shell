# AI Fabric Shell - Enhanced Edition

A modular, AI-powered command-line automation tool with rich Markdown rendering, smart model switching, command history learning, and an extensible plugin system.

## ğŸ¯ Features

- **ğŸ¨ Rich Markdown Rendering** - AI responses display with proper formatting
- **ğŸ¤– Smart Model Management** - Automatic optimal model selection per task
- **ğŸ“Š Model Recommendations** - Get suggestions for different task types
- **ğŸ”§ Plugin System** - YAML-based plugins with model optimization
- **ğŸ“‹ Enhanced UI** - Beautiful tables, syntax highlighting, and progress indicators
- **ğŸš€ Command Generation** - AI-powered one-liner command generation
- **ğŸ” Smart Troubleshooting** - AI analysis of failed commands and scripts
- **âœ¨ Y/N/E Command Options** - Explain commands before executing them
- **ğŸ“š Command History & Learning** - System learns from successful commands
- **ğŸ›¡ï¸ Clean PowerShell Execution** - Runs without profile to avoid Oh My Posh errors

## ğŸ“ Project Structure

```
fabric_shell/
â”œâ”€â”€ __init__.py                 # Package initialization
â”œâ”€â”€ main.py                     # Entry point
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ shell.py               # Main AIFabricShell class
â”‚   â””â”€â”€ system_info.py         # SystemInfo class
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ manager.py             # ModelManager class
â”œâ”€â”€ plugins/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ manager.py             # PluginManager class
â”œâ”€â”€ rendering/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ renderer.py            # ResponseRenderer class
â””â”€â”€ utils/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ commands.py            # Enhanced command execution with history
    â””â”€â”€ extractors.py          # Text/command extraction utilities
```

## ğŸš€ Installation & Setup

### Option 1: Simple Run (Recommended)
1. **Download/Clone the files** to a directory
2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```
3. **Install Ollama**
   ```bash
   # Visit https://ollama.ai for installation instructions
   ollama serve
   ollama pull llama3.1
   ```
4. **Run the shell**
   ```bash
   # Windows
   fabric.bat
   
   # Or use Python directly
   python run.py
   
   # Linux/Mac
   chmod +x fabric.sh
   ./fabric.sh
   
   # Or use Python directly
   python3 run.py
   ```

### Option 2: Install as Package
```bash
# Install in development mode
pip install -e .

# Or install normally
pip install .

# Then run from anywhere
fabric-shell
```

### Option 3: Direct Python Execution
```bash
python main.py
```

## ğŸ“ Required Directory Structure

Make sure your directory looks like this:
```
ai_fabric_shell/
â”œâ”€â”€ main.py                    # Entry point option 1
â”œâ”€â”€ run.py                     # Entry point option 2 (recommended)
â”œâ”€â”€ fabric.bat                 # Windows batch script
â”œâ”€â”€ fabric.sh                  # Unix shell script
â”œâ”€â”€ setup.py                   # Package installation
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ command_history.json       # Auto-created command history
â””â”€â”€ fabric_shell/              # Main package
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ shell.py
    â”‚   â””â”€â”€ system_info.py
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ manager.py
    â”œâ”€â”€ plugins/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ manager.py
    â”œâ”€â”€ rendering/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ renderer.py
    â””â”€â”€ utils/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ commands.py
        â””â”€â”€ extractors.py
```

## ğŸ® Usage

### Core Commands

- **`cmd <task>`** - Generate one-liner commands with Y/N/E options
- **`run <plugin>`** - Execute specific plugin  
- **`list [category]`** - Show plugins (optionally by category)
- **`models`** - Show available AI models with capabilities
- **`switch [model]`** - Switch AI model (interactive if no model specified)
- **`status`** - System status with AI analysis
- **`chat`** - AI chat mode with Markdown rendering
- **`troubleshoot <issue>`** - Quick troubleshooting with formatted output
- **`history`** - View command execution history and success patterns
- **`help`** - Show comprehensive help
- **`quit`** - Exit

### âœ¨ Enhanced Command Flow

When you generate commands, you now get three options:

```bash
fabric(llama3.1)> cmd find large Python files

Generated BASH Command
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ find . -name "*.py" -size +1M -type f   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Execute command? [Y]es/[N]o/[E]xplain: e
```

**Y** - Execute the command immediately  
**N** - Cancel and return to prompt  
**E** - Get AI explanation of what the command does

### ğŸ“š Smart Learning System

After successful execution, the system asks for confirmation:

```bash
Output
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ./scripts/large_script.py              â”‚
â”‚ ./data/process_data.py                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Did this accomplish your goal: 'find large Python files'? [Y]es/[N]o: y
âœ“ Command saved to history as successful
```

- Commands are only saved to history if they **actually solved your problem**
- Future similar requests will reference successful patterns
- View your history with `history` command

### Examples

```bash
# Generate a command with explanation option
cmd find all python files larger than 1MB
# Choose E to explain, then Y to execute

# Run code review plugin with optimal model selection
run code_review

# List development category plugins
list development

# Switch to code-optimized model
switch codellama

# View your successful command history
history

# Get troubleshooting help with formatted output
troubleshoot docker container won't start
```

## ğŸ”§ Plugin Development

Plugins are YAML files stored in the `plugins/` directory:

```yaml
name: "example_plugin"
description: "Example plugin description"
category: "development"
preferred_model: "codellama"  # Optional: specify preferred model
model_category: "code"        # Optional: specify model category

parameters:
  task:
    prompt: "What task would you like to accomplish?"
    type: "string"

prompt: |
  Help the user accomplish this task: {task}
  
  Provide detailed instructions and code examples.

context: |
  The user is working on: {task}

post_process:
  type: "execute"  # Optional: extract and execute code from response
```

## ğŸ¤– Model Management

The shell automatically detects available Ollama models and provides intelligent recommendations:

- **Code Tasks**: CodeLlama, CodeGemma
- **Analysis**: Mixtral, Llama3.2
- **Quick Commands**: Phi3, Mistral
- **Security**: Mixtral, Llama3.2
- **Performance**: Mixtral, Llama3.2

## ğŸ“¦ Dependencies

- **rich** - Terminal UI and Markdown rendering
- **ollama** - AI model interaction
- **PyYAML** - Plugin configuration parsing
- **psutil** - System information gathering

## ğŸ—ï¸ Architecture

### Separation of Concerns

- **`core/shell.py`** - Main application orchestration and command routing
- **`models/manager.py`** - AI model detection, switching, and recommendations
- **`plugins/manager.py`** - Plugin loading, validation, and execution coordination
- **`rendering/renderer.py`** - Markdown rendering and UI formatting
- **`utils/commands.py`** - Enhanced command execution with history tracking and Y/N/E options
- **`utils/extractors.py`** - Text parsing and command extraction from AI responses

### Benefits of Modular Design

- **Maintainable** - Each component has a single responsibility
- **Testable** - Individual modules can be tested in isolation
- **Extensible** - Easy to add new features without affecting existing code
- **Reusable** - Components can be imported and used independently

## âœ¨ Enhanced Features (New!)

### Y/N/E Command Options

Every generated command now offers three choices:
- **[Y]es** - Execute immediately
- **[N]o** - Cancel execution
- **[E]xplain** - Get detailed AI explanation before deciding

### Smart Command Learning

- **Success Tracking**: Only commands that actually solve problems are saved
- **Pattern Recognition**: Similar tasks reference past successful commands
- **Context Injection**: AI gets historical context for better suggestions
- **User Confirmation**: "Did this work?" ensures quality learning data

### Clean PowerShell Execution

- **No Profile Loading**: PowerShell runs with `-NoProfile` flag
- **No Oh My Posh Errors**: Eliminates theme and prompt customization issues
- **Faster Execution**: Skip profile loading delays
- **Consistent Environment**: Same clean PowerShell every time

### Enhanced Error Handling

- **Technical vs Functional Errors**: Distinguishes between execution errors and wrong results
- **Alternative Approaches**: Offers different methods when commands don't meet expectations
- **Smart Troubleshooting**: Context-aware error analysis and fixes

## ğŸ”„ Migration from Previous Versions

The enhanced version maintains 100% compatibility with existing functionality while adding:

1. **Better Command Interaction** - Y/N/E options for all generated commands
2. **Learning System** - Builds knowledge from successful command patterns
3. **Improved Reliability** - Clean PowerShell execution without profile interference
4. **Enhanced User Experience** - Better confirmation flows and error handling

## ğŸ¨ Enhanced Features Details

### Rich Markdown Rendering

AI responses now support:
- Headers (##, ###, ####)
- Code blocks with syntax highlighting
- Lists (bulleted and numbered)
- **Bold** and *italic* text
- Tables
- Links

### Smart Model Selection

- Plugins automatically use optimal models for their tasks
- Model recommendations based on task complexity and type
- Seamless model switching with capability analysis

### Command History Intelligence

```bash
# View your command history
fabric(llama3.1)> history

Command History (Last 10)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Date               â”‚ Task                         â”‚ Command                        â”‚ Shell     â”‚ Status â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2025-01-19 10:30   â”‚ find large Python files     â”‚ find . -name "*.py" -size +1M  â”‚ bash      â”‚ âœ…     â”‚
â”‚ 2025-01-19 10:25   â”‚ check system memory          â”‚ free -h                        â”‚ bash      â”‚ âœ…     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Performance Improvements

- **Faster Command Generation**: Historical context helps AI make better suggestions faster
- **Reduced Trial and Error**: Learn from past successes instead of repeating failures
- **Clean Execution Environment**: No profile loading delays or errors
- **Smart Model Routing**: Right model for each task type automatically

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes in the appropriate module
4. Add tests for new functionality
5. Submit a pull request

## ğŸ“ License

MIT License - feel free to use and modify as needed.

---

## ğŸ†• What's New in This Version

### Version 2.1.0 - Enhanced Command Intelligence

- **ğŸ” Y/N/E Command Options** - Explain any command before executing
- **ğŸ“š Smart Learning System** - Learns from commands that actually work
- **ğŸ›¡ï¸ Clean PowerShell** - No more Oh My Posh or profile errors
- **ğŸ¯ User Confirmation Flow** - Only save commands that solve the actual problem
- **ğŸ”„ Alternative Approaches** - Get different methods when first attempt doesn't work
- **ğŸ“Š Enhanced History** - View and learn from successful command patterns

Ready to automate with enhanced AI intelligence! ğŸ¯